{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "from typing import Optional, Tuple\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "compiled_labels_path = 'compiled_labels.csv'\n",
    "img_dir = './faces'\n",
    "\n",
    "if not os.path.exists(compiled_labels_path):\n",
    "    json_file_path = 'training_raw_data.json'\n",
    "    with open(json_file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    emotion_list = ['adoration', 'affection', 'aggravation', 'agitation', 'agony', 'alarm', 'alienation', 'amazement', 'amusement', 'anger', 'anguish', 'annoyance', 'anxiety', 'apprehension', 'arousal', 'astonishment', 'attraction', 'bitterness', 'bliss', 'caring', 'cheerfulness', 'compassion', 'contempt', 'contentment', 'defeat', 'dejection', 'delight', 'depression', 'desire', 'despair', 'disappointment', 'disgust', 'dislike', 'dismay', 'displeasure', 'distress', 'dread', 'eagerness', 'ecstasy', 'elation', 'embarrassment', 'enjoyment', 'enthrallment', 'enthusiasm', 'envy', 'euphoria', 'exasperation', 'excitement', 'exhilaration', 'fear', 'ferocity', 'fondness', 'fright', 'frustration', 'fury', 'gaiety', 'gladness', 'glee', 'gloom', 'glumness', 'grief', 'grouchiness', 'grumpiness', 'guilt', 'happiness', 'hate', 'homesickness', 'hope', 'hopelessness', 'horror', 'hostility', 'humiliation', 'hurt', 'hysteria', 'infatuation', 'insecurity', 'insult', 'irritation', 'isolation', 'jealousy', 'jolliness', 'joviality', 'joy', 'jubilation', 'liking', 'loathing', 'loneliness', 'longing', 'love', 'lust', 'melancholy', 'misery', 'mortification', 'neglect', 'nervousness', 'optimism', 'outrage', 'panic', 'passion', 'pity', 'pleasure', 'pride', 'rage', 'rapture', 'regret', 'rejection', 'relief', 'remorse', 'resentment', 'revulsion', 'sadness', 'satisfaction', 'scorn', 'sentimentality', 'shame', 'shock', 'sorrow', 'spite', 'suffering', 'surprise', 'sympathy', 'tenderness', 'tenseness', 'terror', 'thrill', 'torment', 'triumph', 'uneasiness', 'unhappiness', 'vengefulness', 'woe', 'worry', 'wrath', 'zeal', 'zest']\n",
    "\n",
    "    label_to_idx = {emotion: idx for idx, emotion in enumerate(emotion_list)}\n",
    "\n",
    "    labels = []\n",
    "\n",
    "    for image in data:\n",
    "        labels.append(label_to_idx[image['label']])\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    df['Label'] = labels\n",
    "    df['Name'] = [str(i) + \".jpg\" for i in range(len(df))]\n",
    "\n",
    "    valid_images = []\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Checking image paths\"):\n",
    "        img_path = os.path.join(img_dir, row['Name'])\n",
    "        if os.path.exists(img_path):\n",
    "            valid_images.append(idx)\n",
    "\n",
    "    df = df.iloc[valid_images].reset_index(drop=True)\n",
    "    df.to_csv(compiled_labels_path, index=False)\n",
    "else:\n",
    "    df = pd.read_csv(compiled_labels_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, img_dir: str, transform: Optional[transforms.Compose] = None):\n",
    "        self.df = df\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform if transform is not None else transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                              std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, int]:\n",
    "        img_path = os.path.join(self.img_dir, self.df.iloc[idx]['Name'])\n",
    "        \n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            \n",
    "            label = self.df.iloc[idx]['Label']\n",
    "            return image, label\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_path}: {str(e)}\")\n",
    "            return torch.zeros((3, 224, 224)), -1\n",
    "\n",
    "class EmotionClassifier(nn.Module):\n",
    "    def __init__(self, num_classes: int = 135, pretrained: bool = True):\n",
    "        super(EmotionClassifier, self).__init__()\n",
    "        self.resnet = models.resnet101(pretrained=pretrained)\n",
    "        \n",
    "        num_features = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Sequential(\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "        for param in self.resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        for param in self.resnet.layer4.parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in self.resnet.layer3.parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in self.resnet.fc.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.resnet(x)\n",
    "\n",
    "def create_data_loaders(df: pd.DataFrame, \n",
    "                       img_dir: str, \n",
    "                       batch_size: int = 32,\n",
    "                       train_split: float = 0.95,\n",
    "                       num_workers: int = 4) -> Tuple[DataLoader, DataLoader]:\n",
    "    dataset = EmotionDataset(df, img_dir)\n",
    "    \n",
    "    train_size = int(train_split * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "        dataset, [train_size, val_size]\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        drop_last=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        drop_last=False\n",
    "    )\n",
    "    \n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device {device}\")\n",
    "\n",
    "train_loader, val_loader = create_data_loaders(\n",
    "    df=df,\n",
    "    img_dir='./faces',\n",
    "    batch_size=128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/export/home/acs/stud/c/cconstantinescu2705/.conda/envs/llm/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/export/home/acs/stud/c/cconstantinescu2705/.conda/envs/llm/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Epoch 1/20 [Train]: 100%|██████████████████████████████████████████████| 3836/3836 [37:43<00:00,  1.69it/s, loss=3.4608]\n",
      "Epoch 1/20 [Valid]: 100%|████████████████████████████████████| 202/202 [01:54<00:00,  1.77it/s, loss=3.2453, acc=16.30%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model with accuracy 16.30%\n",
      "Epoch 1/20:\n",
      "Training Loss: 3.4608\n",
      "Validation Loss: 3.2453\n",
      "Validation Accuracy: 16.30%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 [Train]: 100%|██████████████████████████████████████████████| 3836/3836 [06:37<00:00,  9.65it/s, loss=3.1862]\n",
      "Epoch 2/20 [Valid]: 100%|████████████████████████████████████| 202/202 [00:11<00:00, 17.18it/s, loss=3.1383, acc=17.81%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model with accuracy 17.81%\n",
      "Epoch 2/20:\n",
      "Training Loss: 3.1862\n",
      "Validation Loss: 3.1383\n",
      "Validation Accuracy: 17.81%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 [Train]: 100%|██████████████████████████████████████████████| 3836/3836 [06:15<00:00, 10.21it/s, loss=3.0518]\n",
      "Epoch 3/20 [Valid]: 100%|████████████████████████████████████| 202/202 [00:11<00:00, 18.32it/s, loss=3.0263, acc=19.03%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model with accuracy 19.03%\n",
      "Epoch 3/20:\n",
      "Training Loss: 3.0518\n",
      "Validation Loss: 3.0263\n",
      "Validation Accuracy: 19.03%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 [Train]: 100%|██████████████████████████████████████████████| 3836/3836 [06:18<00:00, 10.14it/s, loss=2.9415]\n",
      "Epoch 4/20 [Valid]: 100%|████████████████████████████████████| 202/202 [00:11<00:00, 17.98it/s, loss=2.9747, acc=20.75%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model with accuracy 20.75%\n",
      "Epoch 4/20:\n",
      "Training Loss: 2.9415\n",
      "Validation Loss: 2.9747\n",
      "Validation Accuracy: 20.75%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 [Train]: 100%|██████████████████████████████████████████████| 3836/3836 [06:21<00:00, 10.04it/s, loss=2.8359]\n",
      "Epoch 5/20 [Valid]: 100%|████████████████████████████████████| 202/202 [00:11<00:00, 17.78it/s, loss=2.9575, acc=20.80%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model with accuracy 20.80%\n",
      "Epoch 5/20:\n",
      "Training Loss: 2.8359\n",
      "Validation Loss: 2.9575\n",
      "Validation Accuracy: 20.80%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 [Train]: 100%|██████████████████████████████████████████████| 3836/3836 [06:22<00:00, 10.04it/s, loss=2.7287]\n",
      "Epoch 6/20 [Valid]: 100%|████████████████████████████████████| 202/202 [00:11<00:00, 17.91it/s, loss=2.9569, acc=21.32%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model with accuracy 21.32%\n",
      "Epoch 6/20:\n",
      "Training Loss: 2.7287\n",
      "Validation Loss: 2.9569\n",
      "Validation Accuracy: 21.32%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 [Train]: 100%|██████████████████████████████████████████████| 3836/3836 [06:22<00:00, 10.02it/s, loss=2.6184]\n",
      "Epoch 7/20 [Valid]: 100%|████████████████████████████████████| 202/202 [00:11<00:00, 17.28it/s, loss=2.9659, acc=21.18%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20:\n",
      "Training Loss: 2.6184\n",
      "Validation Loss: 2.9659\n",
      "Validation Accuracy: 21.18%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 [Train]: 100%|██████████████████████████████████████████████| 3836/3836 [06:23<00:00, 10.01it/s, loss=2.5010]\n",
      "Epoch 8/20 [Valid]: 100%|████████████████████████████████████| 202/202 [00:11<00:00, 17.78it/s, loss=2.9973, acc=21.71%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model with accuracy 21.71%\n",
      "Epoch 8/20:\n",
      "Training Loss: 2.5010\n",
      "Validation Loss: 2.9973\n",
      "Validation Accuracy: 21.71%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 [Train]: 100%|██████████████████████████████████████████████| 3836/3836 [06:26<00:00,  9.94it/s, loss=2.3800]\n",
      "Epoch 9/20 [Valid]: 100%|████████████████████████████████████| 202/202 [00:11<00:00, 17.39it/s, loss=3.1324, acc=21.31%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20:\n",
      "Training Loss: 2.3800\n",
      "Validation Loss: 3.1324\n",
      "Validation Accuracy: 21.31%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 [Train]: 100%|█████████████████████████████████████████████| 3836/3836 [06:24<00:00,  9.97it/s, loss=2.2586]\n",
      "Epoch 10/20 [Valid]: 100%|███████████████████████████████████| 202/202 [00:11<00:00, 17.36it/s, loss=3.1488, acc=21.58%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20:\n",
      "Training Loss: 2.2586\n",
      "Validation Loss: 3.1488\n",
      "Validation Accuracy: 21.58%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 [Train]: 100%|█████████████████████████████████████████████| 3836/3836 [06:39<00:00,  9.61it/s, loss=2.1417]\n",
      "Epoch 11/20 [Valid]: 100%|███████████████████████████████████| 202/202 [00:11<00:00, 17.34it/s, loss=3.2386, acc=21.33%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20:\n",
      "Training Loss: 2.1417\n",
      "Validation Loss: 3.2386\n",
      "Validation Accuracy: 21.33%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 [Train]: 100%|█████████████████████████████████████████████| 3836/3836 [06:25<00:00,  9.95it/s, loss=2.0270]\n",
      "Epoch 12/20 [Valid]: 100%|███████████████████████████████████| 202/202 [00:11<00:00, 17.53it/s, loss=3.3883, acc=21.06%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20:\n",
      "Training Loss: 2.0270\n",
      "Validation Loss: 3.3883\n",
      "Validation Accuracy: 21.06%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20 [Train]: 100%|█████████████████████████████████████████████| 3836/3836 [06:25<00:00,  9.95it/s, loss=1.9172]\n",
      "Epoch 13/20 [Valid]: 100%|███████████████████████████████████| 202/202 [00:11<00:00, 17.03it/s, loss=3.4207, acc=20.68%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20:\n",
      "Training Loss: 1.9172\n",
      "Validation Loss: 3.4207\n",
      "Validation Accuracy: 20.68%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20 [Train]:   3%|█▏                                             | 99/3836 [00:10<06:45,  9.21it/s, loss=1.6909]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m# Update running loss and progress bar\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m     running_loss \u001b[38;5;241m=\u001b[39m (running_loss \u001b[38;5;241m*\u001b[39m batch_idx \u001b[38;5;241m+\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()) \u001b[38;5;241m/\u001b[39m (batch_idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     35\u001b[0m     train_pbar\u001b[38;5;241m.\u001b[39mset_postfix({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrunning_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m})\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Validation phase\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = EmotionClassifier(num_classes=135)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "best_acc = 21.0\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Train]')\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for batch_idx, (images, labels) in enumerate(train_pbar):\n",
    "        if -1 in labels:\n",
    "            continue\n",
    "            \n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss = (running_loss * batch_idx + loss.item()) / (batch_idx + 1)\n",
    "        train_pbar.set_postfix({'loss': f'{running_loss:.4f}'})\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        val_pbar = tqdm(val_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Valid]')\n",
    "        \n",
    "        for batch_idx, (images, labels) in enumerate(val_pbar):\n",
    "            if -1 in labels:\n",
    "                continue\n",
    "                \n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            val_loss = (val_loss * batch_idx + loss.item()) / (batch_idx + 1)\n",
    "            val_pbar.set_postfix({\n",
    "                'loss': f'{val_loss:.4f}',\n",
    "                'acc': f'{100 * correct / total:.2f}%'\n",
    "            })\n",
    "        \n",
    "        if epoch == 0 or (100 * correct / total) > best_acc:\n",
    "            best_acc = 100 * correct / total\n",
    "            with open('best_model.pkl', 'wb') as f:\n",
    "                torch.save(model.state_dict(), f)\n",
    "            print(f'Saving best model with accuracy {best_acc:.2f}%')\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{num_epochs}:')\n",
    "    print(f'Training Loss: {running_loss:.4f}')\n",
    "    print(f'Validation Loss: {val_loss:.4f}')\n",
    "    print(f'Validation Accuracy: {100 * correct / total:.2f}%\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
